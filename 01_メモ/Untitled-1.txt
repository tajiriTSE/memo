
■手塚さんへの質問
設定するときのモード
モードごとのふるまい
機種切り替え機能、機種ごとにモデル？扱い
検査のしきい値を決める、学習のやり方
量産稼働のやり方、

■サーバー側
モデはweights
utils、ssdファイルを足す
object_detectionのコードは変えていない
チェイナーのssdをそのまま使っている
データローダー.pyの中に入っている、学習コードは入っていない

注意点
モデルは１つのみを固定して読み込んでいるかも
ファイルの出力先、検証用にいくつかかえている

■問題
pythonのバージョン、パイトーチのバージョンと比較

■ユースケース
人が何をやってプログラムを動かすのか明確にする
インストール、学習のやり方、量産稼働

■寄居
ソフトが起動すること、のみを確認している
PC、共通IDでログインしている、寄居は
他の拠点は別で確認する必要がある
北米は手塚さんが聞いてみる

クラサバ、クライアントの共通IDは現場で管理している
サーバー側は現場の人は触れない

・モード　マニュアルモード
画像を表示してOKNGを使うモードは使用している
過検出かどうかを確認している、目視で確認している
マスタと今回の画像を比較して判断する

・完全マニュアル
サーバー側解析がない
完全に人のみが扱う
例えばサーバー側おちたときなど

・モードに応じて2台用意している
ポートを分けて待機が2つある

・LET
機種が来たら、機種用のTCP送信先をもっている
機種用のダミーコードはTCP

・同時アクセス
LETから同時に来る場合、
画像の検査がながい場合がある
検査工程ABCがある、Aだけで画像検査すると次の検査が

検査結果が入れ替わる、検査が止まる

・学習方法について
パイトーチに置き換えるから変わるけど
学習済みのモデルをTW→TSEにもらうから、学習方法を知る必要はない

・７は設定をしている
現場用のPCで設定
３代目のIFアプリ用が、

■システム構成
LETーCーS
　 ーC ↑
サーバーの中にアプリが２台、クライアントと１：１でしかいられないから
SのIP/PORTはべつでかえているが、それ以外のマスタ画像などは同じものをみている
同じ結果が欲しいから、２つは自動・手動のモードで分けているだけである
結果を出力するフォルダは分けている
SのPCにCをいれて、７の設定を行っている、運用中は設定操作をできないため

■YMTO
どのくるまだよを表す　例えばフリードだよみたいな
YMTO=YMMM-TTT-OOO
FILE=TMMM_TTTT_OOO_CAMERA_STATION
%はワイルドカード
LTY3%_%_%_B5_02　B5がカメラ、０２が号機

AIMING_IDの中にStationがいる、Aiming回数、カメラの情報が入っている

feature_value

X1Y1などはxmlからクロスポイントの設定

LETのエイミングポイント、図のマーカーの従事の部分を４点

全て％のファイル、サーバー側でNGが出ると止まっちゃうから、とりあえずNGを返すように入れている

■設定ファイルを作る
merge_image.bat、マスタイメージとフォルダ構成を作ってくれる
data/editsetting/merge_images
merge_imagesというフォルダが有る、画像をたくさん入れて
どれを基準にするというのを決める、baseという名前の画像

■作る順番
master_image　Batchでサーバー側で作る　ばらつき含んだ画像　JPGで食わせる
masking-area　クライアントの７版機能　判定力を弱めたいエリアを決める
Unitspace　サーバー内のバッチ　２を元に、１００枚集めて、物理的な、エッヂの違いなど、マスタ画像との違いをだす　JPGで食わせる
feature_value　ローカルPCで　ユニットスペースファイル内に４０項目がある、どの列を使うかという指定
parameter-setting　どんなしきい値で、サーバーで手動、クロスポイントもある

UnitSpaceを決めるときに、クロスポイントも決められてしまう
ユニットスペース用の動きになる、UnitSpaceフォルダの画像の検査、Unitspaceファイルに書き込む
クロスポイントの判定をしたうえで

クロスポイントの値を持っていない、サーバーで計算した値が違うからUnitSpaceの計算を止めるというプログラムになっている
仮値を送っている５０、画像のクロスポイントは自動で計算している２００

tool/create_unitspace.bat
utils/create_unitspace.py
↑３のバッチ
借り地とぜんぜん違うから、NGをだねという判断をしちゃっている
create_unit_spaceフォルダがあって、そこん画像１枚ずつに対してグるぐるまわしている
出てきたUnitSpaceの結果を、ファイルとして出力する
ぼやけ判定のラプラシアン・FFT・RGBによるぼやけ判定、の結果を出すための計算途中の結果をファイルへ出力している
└Result　マハラノビスの距離

■JuSE-StatWorks5、総合編
統計の処理、手法選択、品質工学、MT法、
単位データタブに、UnitSpace.csvの中身を丸ごとコピー、データ貼り付け
マハラノビスの距離を計算しようとしても動かない、
モニタリングタブ（本来はここでOK/NGをわける）、正規分布が見られる
変数情報で、列の仕様不使用を決める
そうかんが高い、座高と体重
そうかんがない値を選ぼうとしている

※日本語版しかない、北米でどうするか

■RGBAreaSetting
FileImport、もらったフォルダ群、masking_area、Jsonファイルを選択すると
Json、MasterImageのファイルを参照している、同じ階層のディレクトリにある前提
座標が書いてある、座標値を絵で表現している

MasterImage
画像から、マスクエリアを作るやつ
ここで画像を参照するから、最初のバッチでフォルダ構成を作る

■
左上が検査画像、右上がますた
右下が、RGB差分　差分が大きいと白くなる
左下、検査値の

自動モードの場合はResultフォルダに自動で
手動モードの場合はxmlを自動で保存、
LETは解析PCからの結果だけを受け取っている

■
手動モードで、IFアプリで人が操作しなかったら、
LET側でタイムアウトしてエラーになる

■
キューにためた処理を、先頭から１つずつ

■ああ
editsetting/merge_images
似たような画像を作る
base.jpgに名前を変える、バッチ動かす
フォルダ構成が作られる、中にマスターイメージが作られる

■UnitSpace
手塚さん経由で

